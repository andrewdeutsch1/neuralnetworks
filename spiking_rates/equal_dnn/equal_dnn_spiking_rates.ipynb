{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spiking Rates for a model with 5 dense layers of equal neurons"
      ],
      "metadata": {
        "id": "dcnlPIjC5ewO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import nengo\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import nengo_dl\r\n",
        "import copy\r\n",
        "\r\n",
        "seed = 0\r\n",
        "np.random.seed(seed)\r\n",
        "tf.random.set_seed(seed)"
      ],
      "outputs": [],
      "metadata": {
        "id": "z0oTxL6w5ewR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# obtain images\r\n",
        "(train_images, train_labels), (test_images,test_labels) = tf.keras.datasets.cifar10.load_data()\r\n",
        "\r\n",
        "# normalize data by color channel\r\n",
        "def normalize(array):\r\n",
        "    return (array - np.mean(array)) / np.std(array)\r\n",
        "\r\n",
        "train_images_R = normalize(train_images.transpose()[0].transpose())\r\n",
        "train_images_G = normalize(train_images.transpose()[1].transpose())\r\n",
        "train_images_B = normalize(train_images.transpose()[2].transpose())\r\n",
        "test_images_R = normalize(test_images.transpose()[0].transpose())\r\n",
        "test_images_G = normalize(test_images.transpose()[1].transpose())\r\n",
        "test_images_B = normalize(test_images.transpose()[2].transpose())\r\n",
        "\r\n",
        "train_images = np.array([train_images_R, train_images_G, train_images_B])\r\n",
        "test_images = np.array([test_images_R, test_images_G, test_images_B])\r\n",
        "\r\n",
        "train_images = np.moveaxis(train_images, 0, -1)\r\n",
        "test_images = np.moveaxis(test_images, 0, -1)\r\n",
        "\r\n",
        "# verify normalization\r\n",
        "print((train_images.shape, train_labels.shape), (test_images.shape, test_labels.shape))\r\n",
        "print('test mean:', np.mean(train_images))\r\n",
        "print('test stdv:', np.std(train_images))\r\n",
        "print('train mean:', np.mean(test_images))\r\n",
        "print('train stdv:', np.std(test_images))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((50000, 32, 32, 3), (50000, 1)) ((10000, 32, 32, 3), (10000, 1))\n",
            "test mean: 5.4830214442821065e-17\n",
            "test stdv: 1.0000000000000002\n",
            "train mean: 8.14903700074865e-18\n",
            "train stdv: 1.0000000000000002\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# flatten images and add time dimension\r\n",
        "train_images = train_images.reshape((train_images.shape[0], 1, -1))\r\n",
        "train_labels = train_labels.reshape((train_labels.shape[0], 1, -1))\r\n",
        "test_images = test_images.reshape((test_images.shape[0], 1, -1))\r\n",
        "test_labels = test_labels.reshape((test_labels.shape[0], 1, -1))\r\n",
        "\r\n",
        "print((train_images.shape, train_labels.shape), (test_images.shape, test_labels.shape))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((50000, 1, 3072), (50000, 1, 1)) ((10000, 1, 3072), (10000, 1, 1))\n"
          ]
        }
      ],
      "metadata": {
        "id": "MYgW3rU55ewS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build network and convert to nengo-dl"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "inp = tf.keras.Input(shape=(32, 32, 3))\r\n",
        "\r\n",
        "flatten = tf.keras.layers.Flatten()(inp)\r\n",
        "\r\n",
        "# reduced to 200 neurons per layer (75 was too low)\r\n",
        "dense0 = tf.keras.layers.Dense(units=204, activation=tf.nn.relu, name='d0')(flatten)\r\n",
        "dense1 = tf.keras.layers.Dense(units=203, activation=tf.nn.relu, name='d1')(dense0)\r\n",
        "dense2 = tf.keras.layers.Dense(units=202, activation=tf.nn.relu, name='d2')(dense1)\r\n",
        "dense3 = tf.keras.layers.Dense(units=201, activation=tf.nn.relu, name='d3')(dense2)\r\n",
        "dense4 = tf.keras.layers.Dense(units=200, activation=tf.nn.relu, name='d4')(dense3)\r\n",
        "\r\n",
        "out = tf.keras.layers.Dense(units=10)(dense4)\r\n",
        "\r\n",
        "model = tf.keras.Model(inputs=inp, outputs=out)"
      ],
      "outputs": [],
      "metadata": {
        "id": "JZ_bK1AB5ewU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "converter = nengo_dl.Converter(model)"
      ],
      "outputs": [],
      "metadata": {
        "id": "seOy_LqT5ewV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the non-spiking network"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "source": [
        "with nengo_dl.Simulator(converter.net, minibatch_size=200) as sim:\r\n",
        "    \r\n",
        "    sim.compile(\r\n",
        "        optimizer=tf.optimizers.Adam(0.001),\r\n",
        "        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "        metrics=[tf.metrics.sparse_categorical_accuracy]\r\n",
        "    )\r\n",
        "\r\n",
        "    sim.fit(\r\n",
        "        {converter.inputs[inp]: train_images},\r\n",
        "        {converter.outputs[out]: train_labels},\r\n",
        "        validation_data=({converter.inputs[inp]: test_images}, {converter.outputs[out]: test_labels}),\r\n",
        "        epochs=20\r\n",
        "    )\r\n",
        "\r\n",
        "    # save the parameters\r\n",
        "    sim.save_params(\"./3_conv_params\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build finished in 0:00:00                                                      \n",
            "Optimization finished in 0:00:00                                               \n",
            "Construction finished in 0:00:00                                               \n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 39s 79ms/step - loss: 1.8004 - probe_loss: 1.8004 - probe_sparse_categorical_accuracy: 0.3441 - val_loss: 1.3571 - val_probe_loss: 1.3571 - val_probe_sparse_categorical_accuracy: 0.5067\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 19s 76ms/step - loss: 1.3209 - probe_loss: 1.3209 - probe_sparse_categorical_accuracy: 0.5270 - val_loss: 1.2044 - val_probe_loss: 1.2044 - val_probe_sparse_categorical_accuracy: 0.5704\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 1.1490 - probe_loss: 1.1490 - probe_sparse_categorical_accuracy: 0.5938 - val_loss: 1.0642 - val_probe_loss: 1.0642 - val_probe_sparse_categorical_accuracy: 0.6231\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 19s 75ms/step - loss: 1.0186 - probe_loss: 1.0186 - probe_sparse_categorical_accuracy: 0.6429 - val_loss: 0.9830 - val_probe_loss: 0.9830 - val_probe_sparse_categorical_accuracy: 0.6544\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 20s 80ms/step - loss: 0.9409 - probe_loss: 0.9409 - probe_sparse_categorical_accuracy: 0.6722 - val_loss: 0.9459 - val_probe_loss: 0.9459 - val_probe_sparse_categorical_accuracy: 0.6681\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 22s 87ms/step - loss: 0.8663 - probe_loss: 0.8663 - probe_sparse_categorical_accuracy: 0.6979 - val_loss: 0.8864 - val_probe_loss: 0.8864 - val_probe_sparse_categorical_accuracy: 0.6923\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 24s 96ms/step - loss: 0.8032 - probe_loss: 0.8032 - probe_sparse_categorical_accuracy: 0.7195 - val_loss: 0.8820 - val_probe_loss: 0.8820 - val_probe_sparse_categorical_accuracy: 0.6913\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 0.7484 - probe_loss: 0.7484 - probe_sparse_categorical_accuracy: 0.7363 - val_loss: 0.8132 - val_probe_loss: 0.8132 - val_probe_sparse_categorical_accuracy: 0.7180\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 24s 94ms/step - loss: 0.6910 - probe_loss: 0.6910 - probe_sparse_categorical_accuracy: 0.7582 - val_loss: 0.7992 - val_probe_loss: 0.7992 - val_probe_sparse_categorical_accuracy: 0.7201\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 0.6388 - probe_loss: 0.6388 - probe_sparse_categorical_accuracy: 0.7781 - val_loss: 0.7950 - val_probe_loss: 0.7950 - val_probe_sparse_categorical_accuracy: 0.7285\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 24s 98ms/step - loss: 0.5960 - probe_loss: 0.5960 - probe_sparse_categorical_accuracy: 0.7939 - val_loss: 0.7759 - val_probe_loss: 0.7759 - val_probe_sparse_categorical_accuracy: 0.7344\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.5585 - probe_loss: 0.5585 - probe_sparse_categorical_accuracy: 0.8048 - val_loss: 0.8084 - val_probe_loss: 0.8084 - val_probe_sparse_categorical_accuracy: 0.7223\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 24s 97ms/step - loss: 0.5275 - probe_loss: 0.5275 - probe_sparse_categorical_accuracy: 0.8164 - val_loss: 0.7732 - val_probe_loss: 0.7732 - val_probe_sparse_categorical_accuracy: 0.7406\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 26s 105ms/step - loss: 0.4718 - probe_loss: 0.4718 - probe_sparse_categorical_accuracy: 0.8346 - val_loss: 0.7909 - val_probe_loss: 0.7909 - val_probe_sparse_categorical_accuracy: 0.7407\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 0.4564 - probe_loss: 0.4564 - probe_sparse_categorical_accuracy: 0.8399 - val_loss: 0.7959 - val_probe_loss: 0.7959 - val_probe_sparse_categorical_accuracy: 0.7442\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 26s 102ms/step - loss: 0.4209 - probe_loss: 0.4209 - probe_sparse_categorical_accuracy: 0.8540 - val_loss: 0.7752 - val_probe_loss: 0.7752 - val_probe_sparse_categorical_accuracy: 0.7504\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 30s 121ms/step - loss: 0.3794 - probe_loss: 0.3794 - probe_sparse_categorical_accuracy: 0.8679 - val_loss: 0.8021 - val_probe_loss: 0.8021 - val_probe_sparse_categorical_accuracy: 0.7427\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 26s 105ms/step - loss: 0.3559 - probe_loss: 0.3559 - probe_sparse_categorical_accuracy: 0.8786 - val_loss: 0.8229 - val_probe_loss: 0.8229 - val_probe_sparse_categorical_accuracy: 0.7536\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 35s 141ms/step - loss: 0.3092 - probe_loss: 0.3092 - probe_sparse_categorical_accuracy: 0.8959 - val_loss: 0.8490 - val_probe_loss: 0.8490 - val_probe_sparse_categorical_accuracy: 0.7519\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 28s 113ms/step - loss: 0.2945 - probe_loss: 0.2945 - probe_sparse_categorical_accuracy: 0.8963 - val_loss: 0.8382 - val_probe_loss: 0.8382 - val_probe_sparse_categorical_accuracy: 0.7542\n"
          ]
        }
      ],
      "metadata": {
        "id": "Es3hg9Q15ewV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the non-spiking network"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "probed_layers = [dense0, dense1, dense2, dense3, dense4]\r\n",
        "\r\n",
        "probed_layer_to_model_layer_dict = {\r\n",
        "    inp.ref(): model.layers[0],\r\n",
        "    dense0.ref(): model.layers[2],\r\n",
        "    dense1.ref(): model.layers[3],\r\n",
        "    dense2.ref(): model.layers[4],\r\n",
        "    dense3.ref(): model.layers[5],\r\n",
        "    dense4.ref(): model.layers[6],\r\n",
        "    out.ref(): model.layers[7],\r\n",
        "}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "def run_network(\r\n",
        "    activation,\r\n",
        "    params_file=\"equal_dnn_params\",\r\n",
        "    n_steps=30,\r\n",
        "    scale_firing_rates=1,\r\n",
        "    synapse=None,\r\n",
        "    n_test=400,\r\n",
        "    n_images_for_rates=1,\r\n",
        "    n_sample_neurons=100,\r\n",
        "):\r\n",
        "    # convert the keras model to a nengo network\r\n",
        "    nengo_converter = nengo_dl.Converter(\r\n",
        "        model,\r\n",
        "        swap_activations={tf.nn.relu: activation},\r\n",
        "        scale_firing_rates=scale_firing_rates,\r\n",
        "        synapse=synapse,\r\n",
        "    )\r\n",
        "\r\n",
        "    # get input/output objects\r\n",
        "    nengo_input = nengo_converter.inputs[inp]\r\n",
        "    nengo_output = nengo_converter.outputs[out]\r\n",
        "\r\n",
        "    # add a probe to the first convolutional layer to record activity.\r\n",
        "    # we'll only record from a subset of neurons, to save memory.\r\n",
        "    sample_neurons = np.array([\r\n",
        "        np.linspace(0, np.prod(layer.shape[1:]), n_sample_neurons, endpoint=False, dtype=np.int32) for layer in probed_layers\r\n",
        "    ])\r\n",
        "\r\n",
        "    # set probes\r\n",
        "    with nengo_converter.net:\r\n",
        "        probes = np.array([\r\n",
        "            nengo.Probe(nengo_converter.layers[probed_layers[l]][sample_neurons[l]]) for l in range(len(probed_layers))\r\n",
        "        ])\r\n",
        "\r\n",
        "    probe_to_model_layer_dict = { probes[l]: probed_layer_to_model_layer_dict[probed_layers[l].ref()] for l in range(len(probed_layers)) }\r\n",
        "\r\n",
        "    # repeat inputs for some number of timesteps\r\n",
        "    tiled_test_images = np.tile(test_images[:n_test], (1, n_steps, 1))\r\n",
        "\r\n",
        "    # set some options to speed up simulation\r\n",
        "    with nengo_converter.net:\r\n",
        "        nengo_dl.configure_settings(stateful=False)\r\n",
        "\r\n",
        "    # build network, load in trained weights, run inference on test images\r\n",
        "    with nengo_dl.Simulator(nengo_converter.net, minibatch_size=200, progress_bar=False) as nengo_sim:\r\n",
        "        nengo_sim.load_params(params_file)\r\n",
        "        data = nengo_sim.predict({nengo_input: tiled_test_images})\r\n",
        "\r\n",
        "    # compute accuracy on test data, using output of network on\r\n",
        "    # last timestep\r\n",
        "    predictions = np.argmax(data[nengo_output][:, -1], axis=-1)\r\n",
        "    accuracy = (predictions == test_labels[:n_test, 0, 0]).mean()\r\n",
        "    print(f\" test accuracy: {100 * accuracy:.2f}%\")\r\n",
        "\r\n",
        "    rates_for_images = []\r\n",
        "    for image in range(n_images_for_rates):\r\n",
        "        if isinstance(scale_firing_rates, dict):\r\n",
        "            scaled_data = np.array([\r\n",
        "                data[probe][image] * scale_firing_rates[probe_to_model_layer_dict[probe]] for probe in probes\r\n",
        "            ])\r\n",
        "        else:\r\n",
        "            scaled_data = np.array([\r\n",
        "                data[probe][image] * scale_firing_rates for probe in probes\r\n",
        "            ])\r\n",
        "                \r\n",
        "        if isinstance(activation, nengo.SpikingRectifiedLinear) or isinstance(activation, nengo.LIF):\r\n",
        "            scaled_data /= n_sample_neurons\r\n",
        "            layer_rates = np.array([\r\n",
        "                np.sum(scaled_data[i], axis=0) / (n_steps * nengo_sim.dt) for i in range(len(scaled_data))\r\n",
        "            ])\r\n",
        "        else:\r\n",
        "            layer_rates = scaled_data\r\n",
        "\r\n",
        "        rates_for_images.append(layer_rates)\r\n",
        "       \r\n",
        "    avg_layer_rates = np.mean(np.array(rates_for_images), axis=0)\r\n",
        "\r\n",
        "    return (accuracy, avg_layer_rates)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QnjBzML95ewX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "baseline_accuracy, baseline_rates = run_network(activation=nengo.RectifiedLinear(), n_steps=10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F01327C950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F01327C950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " test accuracy: 53.00%\n"
          ]
        }
      ],
      "metadata": {
        "id": "4vChmAYq5ewY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "n_steps=60\r\n",
        "synapse=0.01\r\n",
        "scale_firing_rates=50\r\n",
        "n_images_for_rates=100\r\n",
        "n_sample_neurons=200\r\n",
        "\r\n",
        "spiking_accuracy, spiking_rates = run_network(\r\n",
        "        activation=nengo.SpikingRectifiedLinear(), \r\n",
        "        n_steps=n_steps, \r\n",
        "        synapse=synapse, \r\n",
        "        scale_firing_rates=scale_firing_rates,\r\n",
        "        n_images_for_rates=n_images_for_rates,\r\n",
        "        n_sample_neurons=n_sample_neurons,\r\n",
        "    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F01963DD90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F01963DD90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " test accuracy: 47.00%\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "source": [
        "rate_data.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "source": [
        "spiking_rates[0].shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "source": [
        "# create plots of layer rates\r\n",
        "import seaborn as sns\r\n",
        "sns.set_style(\"white\")\r\n",
        "for l in range(len(spiking_rates)):\r\n",
        "    rate_data = spiking_rates[l]\r\n",
        "\r\n",
        "    plt.xlabel(\"Firing Rate (Hz)\")\r\n",
        "    plt.ylabel(\"Relative Neuron Count\")\r\n",
        "    plt.title(\"Firing Rate Distribution in SNN (Acc.=\" + str(spiking_accuracy) + \")\\n(synapse=\"+str(synapse)+\", scale_firing_rates=\"+str(scale_firing_rates)+\", DNN=\"+str(baseline_accuracy)+\")\")\r\n",
        "    labels = ['dense0', 'dense1', 'dense2', 'dense3', 'dense4']\r\n",
        "\r\n",
        "    kwargs = dict(hist_kws={'alpha':.5}, kde_kws={'linewidth':2})\r\n",
        "    \r\n",
        "    # for l in rate_data:\r\n",
        "    s = sns.distplot(rate_data, bins=20, label=labels[l], color=sns.color_palette()[l], **kwargs)\r\n",
        "    s.legend()\r\n",
        "    plt.savefig(\"./images/individual_layer_\"+str(l)+\"_bar_spiking_rates_\"+str(n_images_for_rates)+\"im_\"+str(synapse)[2:]+\"_\"+str(scale_firing_rates)+\"_neurons=\"+str(n_sample_neurons), dpi=300)\r\n",
        "    plt.close()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
            "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
            "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
            "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
            "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
            "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
            "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
            "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
            "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
            "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "# create plots of layer rates\r\n",
        "rate_data = spiking_rates.swapaxes(0, 1)\r\n",
        "\r\n",
        "plt.xlabel(\"layer\")\r\n",
        "plt.ylabel(\"firing rate (Hz)\")\r\n",
        "plt.title(\"Firing Rate Statistics by Layer of SNN (Acc.=\" + str(spiking_accuracy) + \")\\n(synapse=\"+str(synapse)+\", scale_firing_rates=\"+str(scale_firing_rates)+\", DNN=\"+str(baseline_accuracy)+\")\")\r\n",
        "\r\n",
        "labels = ['dense0', 'dense1', 'dense2', 'dense3', 'dense4']\r\n",
        "plt.boxplot(rate_data, labels=labels, showfliers=True)\r\n",
        "plt.savefig(\"./images/spiking_rates_\"+str(n_images_for_rates)+\"im_\"+str(synapse)[2:]+\"_\"+str(scale_firing_rates)+\"_neurons=\"+str(n_sample_neurons), dpi=300)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "name": "keras-to-snn.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "26130839a7e87fd59e038942810dbb4909e5232b32b1ad521e6a6bc3043702c6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.5 64-bit ('base': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}